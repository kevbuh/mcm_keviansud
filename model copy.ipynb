{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfHDI=pd.read_csv('hdi.csv', on_bad_lines='skip')\n",
    "dfGNI=pd.read_csv('gni.csv', on_bad_lines='skip')\n",
    "dfEdu=pd.read_csv('education_index.csv', on_bad_lines='skip')\n",
    "dfUnemploy=pd.read_csv('unenployment.csv', on_bad_lines='skip')\n",
    "dfHDI.dropna(axis='columns',how='all',inplace=True)\n",
    "dfGNI.dropna(axis='columns',how='all',inplace=True)\n",
    "dfEdu.dropna(axis='columns',how='all',inplace=True)\n",
    "dfUnemploy.dropna(axis='columns',how='all',inplace=True)\n",
    "\n",
    "# dfGNI=dfGNI.applymap(lambda x: x/10000)\n",
    "\n",
    "dfGNIT=dfGNI.transpose()\n",
    "dfHDIT=dfHDI.transpose()\n",
    "dfEduT=dfEdu.transpose()\n",
    "dfUnemployT=dfUnemploy.transpose()\n",
    "\n",
    "dfHDI\n",
    "\n",
    "ArabStatesHDI=dfHDI.loc[['Arab States']]\n",
    "ArabStatesGNI=dfGNI.loc[['Arab States']]\n",
    "ArabStatesEdu=dfEdu.loc[['Arab States']]\n",
    "ArabStatesUnemploy=dfUnemploy.loc[['Arab States']]\n",
    "\n",
    "ArabFrame=[ArabStatesEdu, ArabStatesGNI, ArabStatesUnemploy, ArabStatesHDI]\n",
    "\n",
    "EastAsiaHDI=dfHDI.loc[['East Asia and the Pacific']]\n",
    "EastAsiaGNI=dfGNI.loc[['East Asia and the Pacific']]\n",
    "EastAsiaEdu=dfEdu.loc[['East Asia and the Pacific']]\n",
    "EastAsiaUnemploy=dfUnemploy.loc[['East Asia and the Pacific']]\n",
    "\n",
    "EastAsiaFrame=[EastAsiaEdu, EastAsiaGNI, EastAsiaUnemploy, EastAsiaHDI]\n",
    "\n",
    "EuropeHDI=dfHDI.loc[['Europe and Central Asia']]\n",
    "EuropeGNI=dfGNI.loc[['Europe and Central Asia']]\n",
    "EuropeEdu=dfEdu.loc[['Europe and Central Asia']]\n",
    "EuropeUnemploy=dfUnemploy.loc[['Europe and Central Asia']]\n",
    "\n",
    "EuropeFrame=[EuropeEdu, EuropeGNI, EuropeUnemploy, EuropeHDI]\n",
    "\n",
    "LatinHDI=dfHDI.loc[['Latin America and the Caribbean']]\n",
    "LatinGNI=dfGNI.loc[['Latin America and the Caribbean']]\n",
    "LatinEdu=dfEdu.loc[['Latin America and the Caribbean']]\n",
    "LatinUnemploy=dfUnemploy.loc[['Latin America and the Caribbean']]\n",
    "\n",
    "LatinFrame=[LatinEdu, LatinGNI, LatinUnemploy, LatinHDI]\n",
    "\n",
    "SouthAsiaHDI=dfHDI.loc[['South Asia']]\n",
    "SouthAsiaGNI=dfGNI.loc[['South Asia']]\n",
    "SouthAsiaEdu=dfEdu.loc[['South Asia']]\n",
    "SouthAsiaUnemploy=dfUnemploy.loc[['South Asia']]\n",
    "\n",
    "SouthAsiaFrame=[SouthAsiaEdu,SouthAsiaGNI,SouthAsiaUnemploy, SouthAsiaHDI]\n",
    "\n",
    "AfricanHDI=dfHDI.loc[['Latin America and the Caribbean']]\n",
    "AfricanGNI=dfGNI.loc[['Latin America and the Caribbean']]\n",
    "AfricanEdu=dfEdu.loc[['Latin America and the Caribbean']]\n",
    "AfricanUnemploy=dfUnemploy.loc[['Latin America and the Caribbean']]\n",
    "\n",
    "AfricanFrame=[AfricanEdu, AfricanGNI, AfricanUnemploy, AfricanHDI]\n",
    "\n",
    "\n",
    "IslandHDI=dfHDI.loc[['Small Island Developing States']]\n",
    "IslandGNI=dfGNI.loc[['Small Island Developing States']]\n",
    "IslandEdu=dfEdu.loc[['Small Island Developing States']]\n",
    "IslandUnemploy=dfUnemploy.loc[['Small Island Developing States']]\n",
    "\n",
    "IslandFrame=[IslandEdu, IslandGNI, IslandUnemploy, IslandHDI]\n",
    "\n",
    "\n",
    "\n",
    "dfArab = pd.concat(ArabFrame)\n",
    "dfArab=dfArab.loc[:,'2016':]\n",
    "ArabWeightages=np.linalg.eigvals(dfArab)\n",
    "# WE GOT THE EIGENVALUES Weightages are in order of  EDU, GNI, Unemployment, HDI\n",
    "ArabWeightages\n",
    "\n",
    "\n",
    "dfEastAsia=pd.concat(EastAsiaFrame)\n",
    "dfEastAsia=dfEastAsia.loc[:,'2016':]\n",
    "EastAsiaWeightages=np.linalg.eigvals(dfEastAsia)\n",
    "\n",
    "\n",
    "dfEurope=pd.concat(EuropeFrame)\n",
    "dfEurope=dfEurope.loc[:,'2016':]\n",
    "EuropeWeightages=np.linalg.eigvals(dfEurope)\n",
    "\n",
    "dfLatin=pd.concat(LatinFrame)\n",
    "dfLatin=dfLatin.loc[:,'2016':]\n",
    "LatinWeightages=np.linalg.eigvals(dfEurope)\n",
    "\n",
    "dfAfrica=pd.concat(AfricanFrame)\n",
    "dfAfrica=dfAfrica.loc[:,'2016':]\n",
    "AfricaWeightages=np.linalg.eigvals(dfAfrica)\n",
    "\n",
    "dfSouthAsia=pd.concat(SouthAsiaFrame)\n",
    "dfSouthAsia=dfSouthAsia.loc[:,'2016':]\n",
    "SouthAsiaWeightages=np.linalg.eigvals(dfAfrica)\n",
    "\n",
    "dfIsland=pd.concat(IslandFrame)\n",
    "dfIsland=dfIsland.loc[:,'2016':]\n",
    "Islandweightages=np.linalg.eigvals(dfIsland)\n",
    "\n",
    "\n",
    "\n",
    "ArabAverageHDI=dfHDIT['Arab States'].mean()\n",
    "ArabAverageGNI=dfGNIT['Arab States'].mean()\n",
    "ArabAverageEdu=dfEduT['Arab States'].mean()\n",
    "ArabAverageUnemploy=dfUnemployT['Arab States'].mean()\n",
    "\n",
    "EastAsiaAverageHDI=dfHDIT['East Asia and the Pacific'].mean()\n",
    "EastAsiaAverageGNI=dfGNIT['East Asia and the Pacific'].mean()\n",
    "EastAsiaAverageEdu=dfEduT['East Asia and the Pacific'].mean()\n",
    "EastAsiaAverageUnemploy=dfUnemployT['East Asia and the Pacific'].mean()\n",
    "\n",
    "EuropeAverageHDI=dfHDIT['Europe and Central Asia'].mean()\n",
    "EuropeAverageGNI=dfGNIT['Europe and Central Asia'].mean()\n",
    "EuropeAverageEdu=dfEduT['Europe and Central Asia'].mean()\n",
    "EuropeAverageUnemploy=dfUnemployT['Europe and Central Asia'].mean()\n",
    "\n",
    "LatinAverageHDI=dfHDIT['Latin America and the Caribbean'].mean()\n",
    "LatinAverageGNI=dfGNIT['Latin America and the Caribbean'].mean()\n",
    "LatinAverageEdu=dfEduT['Latin America and the Caribbean'].mean()\n",
    "LatinAverageUnemploy=dfUnemployT['Latin America and the Caribbean'].mean()\n",
    "\n",
    "SouthAsiaAverageHDI=dfHDIT['South Asia'].mean()\n",
    "SouthAsiaAverageGNI=dfGNIT['South Asia'].mean()\n",
    "SouthAsiaAverageEdu=dfEduT['South Asia'].mean()\n",
    "SouthAsiaAverageUnemploy=dfUnemployT['South Asia'].mean()\n",
    "\n",
    "AfricaHDIAverage=dfHDIT['Sub-Saharan Africa'].mean()\n",
    "AfricaGNIAverage=dfGNIT['Sub-Saharan Africa'].mean()\n",
    "AfricaEduAverage=dfEduT['Sub-Saharan Africa'].mean()\n",
    "AfricaUnemployAverage=dfUnemployT['Sub-Saharan Africa'].mean()\n",
    "\n",
    "IslandHDIAverage=dfHDIT['Small Island Developing States'].mean()\n",
    "IslandGNIAverage=dfGNIT['Small Island Developing States'].mean()\n",
    "IslandEduAverage=dfEduT['Small Island Developing States'].mean()\n",
    "IslandUnemployAverage=dfUnemployT['Small Island Developing States'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Normalize(temp_dataset, nCol, weights):\n",
    "    # normalizing the array\n",
    "    # normalizes all the data between 0 and 1\n",
    "    # print(\" Normalizing the DataSet...\\n\")\n",
    "    for i in range(1, nCol):\n",
    "        temp = 0\n",
    "        for j in range(len(temp_dataset)):\n",
    "            temp = temp + temp_dataset.iloc[j, i]**2\n",
    "        temp = temp**0.5\n",
    "        for j in range(len(temp_dataset)):\n",
    "            temp_dataset.iat[j, i] = (\n",
    "                temp_dataset.iloc[j, i] / temp)*weights[i-1]\n",
    "    return temp_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Calc_Values(temp_dataset, nCol, impact):\n",
    "    # print(\" Calculating Positive and Negative values...\\n\")\n",
    "    p_sln = (temp_dataset.max().values)[1:]\n",
    "    n_sln = (temp_dataset.min().values)[1:]\n",
    "    for i in range(1, nCol):\n",
    "        if impact[i-1] == '-':\n",
    "            p_sln[i-1], n_sln[i-1] = n_sln[i-1], p_sln[i-1]\n",
    "    return p_sln, n_sln\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topsis_pipy(temp_dataset, dataset, nCol, weights, impact):\n",
    "    # brings everything together\n",
    "    # normalizing the array\n",
    "    temp_dataset = Normalize(temp_dataset, nCol, weights)\n",
    "\n",
    "    # Calculating positive and negative values\n",
    "    p_sln, n_sln = Calc_Values(temp_dataset, nCol, impact)\n",
    "\n",
    "    # calculating topsis score\n",
    "    # print(\" Generating Score and Rank...\\n\")\n",
    "    score = []\n",
    "    for i in range(len(temp_dataset)):\n",
    "        temp_p, temp_n = 0, 0\n",
    "        for j in range(1, nCol):\n",
    "            temp_p = temp_p + (p_sln[j-1] - temp_dataset.iloc[i, j])**2\n",
    "            temp_n = temp_n + (n_sln[j-1] - temp_dataset.iloc[i, j])**2\n",
    "        temp_p, temp_n = temp_p**0.5, temp_n**0.5\n",
    "        score.append(temp_n/(temp_p + temp_n))\n",
    "    dataset['TOPSIS Score'] = score\n",
    "\n",
    "    # calculating the rank according to topsis score\n",
    "    dataset['Rank'] = (dataset['TOPSIS Score'].rank(\n",
    "        method='max', ascending=False))\n",
    "    dataset = dataset.astype({\"Rank\": int})\n",
    "\n",
    "    print(\"Results:\")\n",
    "    print(\"CI\", dataset)\n",
    "\n",
    "    # dataset.to_csv(\"results.csv\", index=False)\n",
    "    dataset.to_csv(\"results.csv\", index=True, index_label=\"Country\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9.99999868e-01+3.66882126e-08j, -5.10309855e-04+9.61584189e-05j,\n",
       "       -1.40713178e-04-8.76127271e-05j, -6.33250317e-06-8.54571591e-06j])"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "globalarray=np.vstack([Islandweightages,SouthAsiaWeightages,EuropeWeightages,ArabWeightages,AfricaWeightages, EastAsiaWeightages,LatinWeightages])\n",
    "\n",
    "globalDF=pd.DataFrame(globalarray)\n",
    "globalDF.rename(columns={0:'Edu',1:'GNI',2:'Unemployment',3:'HDI'}, inplace=True)\n",
    "\n",
    "globalDF['Edu']=globalDF.Edu.apply(lambda x: x/100)\n",
    "\n",
    "globalEdu=globalDF.Edu.mean()\n",
    "globalEdu\n",
    "\n",
    "globalGNI=globalDF.GNI.mean()\n",
    "\n",
    "globalUnemploy=globalDF.Unemployment.mean()\n",
    "\n",
    "globalHDI=globalDF.HDI.mean()\n",
    "\n",
    "ArrayWeight=np.array([globalEdu, globalGNI,globalUnemploy, globalHDI])\n",
    "\n",
    "# norm=np.linalg.norm(ArrayWeight)\n",
    "\n",
    "# normWeight=ArrayWeight/norm\n",
    "\n",
    "# normWeight\n",
    "\n",
    "def matrixNormalize(data):\n",
    "    K=np.power(np.sum(pow(data,2),axis=0),0.5)\n",
    "    return data/K\n",
    "\n",
    "normArray=matrixNormalize(ArrayWeight) \n",
    "normArray\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
