{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfHDI=pd.read_csv('hdi.csv', on_bad_lines='skip')\n",
    "dfGNI=pd.read_csv('gni.csv', on_bad_lines='skip')\n",
    "dfEdu=pd.read_csv('education_index.csv', on_bad_lines='skip')\n",
    "dfUnemploy=pd.read_csv('unenployment.csv', on_bad_lines='skip')\n",
    "dfHDI.dropna(axis='columns',how='all',inplace=True)\n",
    "dfGNI.dropna(axis='columns',how='all',inplace=True)\n",
    "dfEdu.dropna(axis='columns',how='all',inplace=True)\n",
    "dfUnemploy.dropna(axis='columns',how='all',inplace=True)\n",
    "\n",
    "dfGNI=dfGNI.applymap(lambda x: x/10000)\n",
    "\n",
    "dfGNIT=dfGNI.transpose()\n",
    "dfHDIT=dfHDI.transpose()\n",
    "dfEduT=dfEdu.transpose()\n",
    "dfUnemployT=dfUnemploy.transpose()\n",
    "\n",
    "dfHDI\n",
    "\n",
    "ArabStatesHDI=dfHDI.loc[['Arab States']]\n",
    "ArabStatesGNI=dfGNI.loc[['Arab States']]\n",
    "ArabStatesEdu=dfEdu.loc[['Arab States']]\n",
    "ArabStatesUnemploy=dfUnemploy.loc[['Arab States']]\n",
    "\n",
    "ArabFrame=[ArabStatesEdu, ArabStatesGNI, ArabStatesUnemploy, ArabStatesHDI]\n",
    "\n",
    "EastAsiaHDI=dfHDI.loc[['East Asia and the Pacific']]\n",
    "EastAsiaGNI=dfGNI.loc[['East Asia and the Pacific']]\n",
    "EastAsiaEdu=dfEdu.loc[['East Asia and the Pacific']]\n",
    "EastAsiaUnemploy=dfUnemploy.loc[['East Asia and the Pacific']]\n",
    "\n",
    "EastAsiaFrame=[EastAsiaEdu, EastAsiaGNI, EastAsiaUnemploy, EastAsiaHDI]\n",
    "\n",
    "EuropeHDI=dfHDI.loc[['Europe and Central Asia']]\n",
    "EuropeGNI=dfGNI.loc[['Europe and Central Asia']]\n",
    "EuropeEdu=dfEdu.loc[['Europe and Central Asia']]\n",
    "EuropeUnemploy=dfUnemploy.loc[['Europe and Central Asia']]\n",
    "\n",
    "EuropeFrame=[EuropeEdu, EuropeGNI, EuropeUnemploy, EuropeHDI]\n",
    "\n",
    "LatinHDI=dfHDI.loc[['Latin America and the Caribbean']]\n",
    "LatinGNI=dfGNI.loc[['Latin America and the Caribbean']]\n",
    "LatinEdu=dfEdu.loc[['Latin America and the Caribbean']]\n",
    "LatinUnemploy=dfUnemploy.loc[['Latin America and the Caribbean']]\n",
    "\n",
    "LatinFrame=[LatinEdu, LatinGNI, LatinUnemploy, LatinHDI]\n",
    "\n",
    "SouthAsiaHDI=dfHDI.loc[['South Asia']]\n",
    "SouthAsiaGNI=dfGNI.loc[['South Asia']]\n",
    "SouthAsiaEdu=dfEdu.loc[['South Asia']]\n",
    "SouthAsiaUnemploy=dfUnemploy.loc[['South Asia']]\n",
    "\n",
    "SouthAsiaFrame=[SouthAsiaEdu,SouthAsiaGNI,SouthAsiaUnemploy, SouthAsiaHDI]\n",
    "\n",
    "AfricanHDI=dfHDI.loc[['Latin America and the Caribbean']]\n",
    "AfricanGNI=dfGNI.loc[['Latin America and the Caribbean']]\n",
    "AfricanEdu=dfEdu.loc[['Latin America and the Caribbean']]\n",
    "AfricanUnemploy=dfUnemploy.loc[['Latin America and the Caribbean']]\n",
    "\n",
    "AfricanFrame=[AfricanEdu, AfricanGNI, AfricanUnemploy, AfricanHDI]\n",
    "\n",
    "\n",
    "IslandHDI=dfHDI.loc[['Small Island Developing States']]\n",
    "IslandGNI=dfGNI.loc[['Small Island Developing States']]\n",
    "IslandEdu=dfEdu.loc[['Small Island Developing States']]\n",
    "IslandUnemploy=dfUnemploy.loc[['Small Island Developing States']]\n",
    "\n",
    "IslandFrame=[IslandEdu, IslandGNI, IslandUnemploy, IslandHDI]\n",
    "\n",
    "\n",
    "\n",
    "dfArab = pd.concat(ArabFrame)\n",
    "dfArab=dfArab.loc[:,'2016':]\n",
    "ArabWeightages=np.linalg.eigvals(dfArab)\n",
    "# WE GOT THE EIGENVALUES Weightages are in order of  EDU, GNI, Unemployment, HDI\n",
    "ArabWeightages\n",
    "\n",
    "\n",
    "dfEastAsia=pd.concat(EastAsiaFrame)\n",
    "dfEastAsia=dfEastAsia.loc[:,'2016':]\n",
    "EastAsiaWeightages=np.linalg.eigvals(dfEastAsia)\n",
    "\n",
    "\n",
    "dfEurope=pd.concat(EuropeFrame)\n",
    "dfEurope=dfEurope.loc[:,'2016':]\n",
    "EuropeWeightages=np.linalg.eigvals(dfEurope)\n",
    "\n",
    "dfLatin=pd.concat(LatinFrame)\n",
    "dfLatin=dfLatin.loc[:,'2016':]\n",
    "LatinWeightages=np.linalg.eigvals(dfEurope)\n",
    "\n",
    "dfAfrica=pd.concat(AfricanFrame)\n",
    "dfAfrica=dfAfrica.loc[:,'2016':]\n",
    "AfricaWeightages=np.linalg.eigvals(dfAfrica)\n",
    "\n",
    "dfSouthAsia=pd.concat(SouthAsiaFrame)\n",
    "dfSouthAsia=dfSouthAsia.loc[:,'2016':]\n",
    "SouthAsiaWeightages=np.linalg.eigvals(dfAfrica)\n",
    "\n",
    "dfIsland=pd.concat(IslandFrame)\n",
    "dfIsland=dfIsland.loc[:,'2016':]\n",
    "dfIsland=np.linalg.eigvals(dfIsland)\n",
    "\n",
    "\n",
    "\n",
    "ArabAverageHDI=dfHDIT['Arab States'].mean()\n",
    "ArabAverageGNI=dfGNIT['Arab States'].mean()\n",
    "ArabAverageEdu=dfEduT['Arab States'].mean()\n",
    "ArabAverageUnemploy=dfUnemployT['Arab States'].mean()\n",
    "\n",
    "EastAsiaAverageHDI=dfHDIT['East Asia and the Pacific'].mean()\n",
    "EastAsiaAverageGNI=dfGNIT['East Asia and the Pacific'].mean()\n",
    "EastAsiaAverageEdu=dfEduT['East Asia and the Pacific'].mean()\n",
    "EastAsiaAverageUnemploy=dfUnemployT['East Asia and the Pacific'].mean()\n",
    "\n",
    "EuropeAverageHDI=dfHDIT['Europe and Central Asia'].mean()\n",
    "EuropeAverageGNI=dfGNIT['Europe and Central Asia'].mean()\n",
    "EuropeAverageEdu=dfEduT['Europe and Central Asia'].mean()\n",
    "EuropeAverageUnemploy=dfUnemployT['Europe and Central Asia'].mean()\n",
    "\n",
    "LatinAverageHDI=dfHDIT['Latin America and the Caribbean'].mean()\n",
    "LatinAverageGNI=dfGNIT['Latin America and the Caribbean'].mean()\n",
    "LatinAverageEdu=dfEduT['Latin America and the Caribbean'].mean()\n",
    "LatinAverageUnemploy=dfUnemployT['Latin America and the Caribbean'].mean()\n",
    "\n",
    "SouthAsiaAverageHDI=dfHDIT['South Asia'].mean()\n",
    "SouthAsiaAverageGNI=dfGNIT['South Asia'].mean()\n",
    "SouthAsiaAverageEdu=dfEduT['South Asia'].mean()\n",
    "SouthAsiaAverageUnemploy=dfUnemployT['South Asia'].mean()\n",
    "\n",
    "AfricaHDIAverage=dfHDIT['Sub-Saharan Africa'].mean()\n",
    "AfricaGNIAverage=dfGNIT['Sub-Saharan Africa'].mean()\n",
    "AfricaEduAverage=dfEduT['Sub-Saharan Africa'].mean()\n",
    "AfricaUnemployAverage=dfUnemployT['Sub-Saharan Africa'].mean()\n",
    "\n",
    "IslandHDIAverage=dfHDIT['Small Island Developing States'].mean()\n",
    "IslandGNIAverage=dfGNIT['Small Island Developing States'].mean()\n",
    "IslandEduAverage=dfEduT['Small Island Developing States'].mean()\n",
    "IslandUnemployAverage=dfUnemployT['Small Island Developing States'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Normalize(temp_dataset, nCol, weights):\n",
    "    # normalizing the array\n",
    "    # normalizes all the data between 0 and 1\n",
    "    # print(\" Normalizing the DataSet...\\n\")\n",
    "    for i in range(1, nCol):\n",
    "        temp = 0\n",
    "        for j in range(len(temp_dataset)):\n",
    "            temp = temp + temp_dataset.iloc[j, i]**2\n",
    "        temp = temp**0.5\n",
    "        for j in range(len(temp_dataset)):\n",
    "            temp_dataset.iat[j, i] = (\n",
    "                temp_dataset.iloc[j, i] / temp)*weights[i-1]\n",
    "    return temp_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Calc_Values(temp_dataset, nCol, impact):\n",
    "    # print(\" Calculating Positive and Negative values...\\n\")\n",
    "    p_sln = (temp_dataset.max().values)[1:]\n",
    "    n_sln = (temp_dataset.min().values)[1:]\n",
    "    for i in range(1, nCol):\n",
    "        if impact[i-1] == '-':\n",
    "            p_sln[i-1], n_sln[i-1] = n_sln[i-1], p_sln[i-1]\n",
    "    return p_sln, n_sln\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topsis(temp_dataset, dataset, nCol, weights, impact):\n",
    "    # brings everything together\n",
    "    # normalizing the array\n",
    "    temp_dataset = Normalize(temp_dataset, nCol, weights)\n",
    "\n",
    "    # Calculating positive and negative values\n",
    "    p_sln, n_sln = Calc_Values(temp_dataset, nCol, impact)\n",
    "\n",
    "    # calculating topsis score\n",
    "    # print(\" Generating Score and Rank...\\n\")\n",
    "    score = []\n",
    "    for i in range(len(temp_dataset)):\n",
    "        temp_p, temp_n = 0, 0\n",
    "        for j in range(1, nCol):\n",
    "            temp_p = temp_p + (p_sln[j-1] - temp_dataset.iloc[i, j])**2\n",
    "            temp_n = temp_n + (n_sln[j-1] - temp_dataset.iloc[i, j])**2\n",
    "        temp_p, temp_n = temp_p**0.5, temp_n**0.5\n",
    "        score.append(temp_n/(temp_p + temp_n))\n",
    "    dataset['TOPSIS Score'] = score\n",
    "\n",
    "    # calculating the rank according to topsis score\n",
    "    dataset['Rank'] = (dataset['TOPSIS Score'].rank(\n",
    "        method='max', ascending=False))\n",
    "    dataset = dataset.astype({\"Rank\": int})\n",
    "\n",
    "    print(\"Results:\")\n",
    "    print(\"CI\", dataset)\n",
    "\n",
    "    # dataset.to_csv(\"results.csv\", index=False)\n",
    "    dataset.to_csv(\"results.csv\", index=True, index_label=\"Country\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy Data:\n",
      "                 HDI  Education  Inequality\n",
      "Country                                    \n",
      "Afghanistan    0.511      0.414        28.2\n",
      "Australia      0.944      0.924         8.0\n",
      "Brazil         0.765      0.694        23.8\n",
      "Germany        0.947      0.943         7.9\n",
      "United States  0.926      0.900        12.4\n",
      "\n",
      "Results:\n",
      "CI    TOPSIS Score  Rank\n",
      "0      0.001421     5\n",
      "1      0.964056     2\n",
      "2      0.529301     4\n",
      "3      0.998579     1\n",
      "4      0.918708     3\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"data.csv\")\n",
    "data.set_index('Country', inplace=True)\n",
    "newData = pd.DataFrame()\n",
    "\n",
    "\n",
    "print(\"Dummy Data:\")\n",
    "print(data)\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "nCol = len(data.columns.values)\n",
    "weights = [1.32002308e+01,  1.10763894e-02, -6.95657256e-03, -4.89506072e-02]\n",
    "impact = ['+', '+', '+','+']\n",
    "\n",
    "# need to show country in result\n",
    "# test with large dataset\n",
    "results = topsis(data, newData, nCol, weights, impact)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
